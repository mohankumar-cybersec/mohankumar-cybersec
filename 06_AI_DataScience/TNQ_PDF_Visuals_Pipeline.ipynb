{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TNQ PDF Visuals Pipeline\n",
    "**Author:** Mohankumar E M\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive pipeline for extracting, analyzing, and verifying visual content from PDF documents. It is designed to automate the processing of scientific papers or technical documents.\n",
    "\n",
    "## Pipeline Modules\n",
    "1. **PDF Figure Extraction**: Extracts images and their corresponding captions.\n",
    "2. **Table Detection & Parsing**: Identifies tables and converts them into structured CSV data.\n",
    "3. **OCR & Text Extraction**: Extracts embedded text from non-table figures.\n",
    "4. **Metadata Enrichment**: Categorizes figures and generates keywords using NLP.\n",
    "5. **Figure Complexity Estimator**: Estimates the visual complexity of figures using a Machine Learning model.\n",
    "6. **AI-Generated Content Verification**: Analyzes captions and text to detect potential AI-generated content.\n",
    "\n",
    "## Usage\n",
    "1. Set the `PDF_PATH` variable in the **Setup** section to your target PDF file.\n",
    "2. Run all cells to execute the pipeline.\n",
    "3. Check the generated `.csv` and `.json` files for results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install PyMuPDF pytesseract pdf2image pandas pillow opencv-python scikit-learn transformers nltk\n",
    "!apt-get install poppler-utils tesseract-ocr\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK data\n",
    "try:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    stop_words = set(['the', 'and', 'of', 'in', 'to', 'a', 'is', 'for', 'on', 'with'])\n",
    "\n",
    "# Configuration\n",
    "PDF_PATH = \"sample_paper.pdf\"  # Change this to your PDF file path\n",
    "OUTPUT_DIR = \"output_results\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    print(f\"Created output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Module 1: PDF Figure Extraction\n",
    "Extracts figures and captions from the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_figures_with_captions(pdf_path, output_dir):\n",
    "    \"\"\"\n",
    "    Extracts all figures with their captions from a PDF file.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"MODULE 1: PDF FIGURE EXTRACTION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"Error: File {pdf_path} not found! Please upload a PDF or check the path.\")\n",
    "        # Returning mock data for demonstration if file is missing\n",
    "        return get_mock_figures_data()\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        print(f\" PDF opened successfully: {pdf_path}\")\n",
    "        print(f\" Total pages: {len(doc)}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error opening PDF: {e}\")\n",
    "        return []\n",
    "\n",
    "    figures = []\n",
    "    figure_count = 0\n",
    "\n",
    "    # 1. Extract Captions from Text\n",
    "    print(\"\\n Scanning for captions in document...\")\n",
    "    full_text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        full_text += doc[page_num].get_text()\n",
    "\n",
    "    # Regex to find Figure captions (e.g., \"Figure 1: ...\")\n",
    "    figure_pattern = r'Figure\\s+(\\d+)[:\\-]\\s*([^\\n\\r]+)'\n",
    "    figure_matches = re.findall(figure_pattern, full_text, re.IGNORECASE)\n",
    "    print(f\" Found {len(figure_matches)} figure captions in text\")\n",
    "\n",
    "    caption_dict = {}\n",
    "    for match in figure_matches:\n",
    "        fig_num = match[0]\n",
    "        caption = match[1].strip()\n",
    "        caption_dict[fig_num] = caption\n",
    "\n",
    "    # 2. Extract Images\n",
    "    print(\"\\n Extracting images from pages...\")\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        image_list = page.get_images()\n",
    "\n",
    "        if image_list:\n",
    "             print(f\" Page {page_num+1}: Found {len(image_list)} images\")\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            try:\n",
    "                xref = img[0]\n",
    "                pix = fitz.Pixmap(doc, xref)\n",
    "\n",
    "                # Filter out small icons or artifacts\n",
    "                if pix.n - pix.alpha < 4 and pix.width > 50 and pix.height > 50:\n",
    "                    figure_count += 1\n",
    "                    filename = os.path.join(output_dir, f\"Figure_{figure_count}.png\")\n",
    "\n",
    "                    # Save image\n",
    "                    if pix.n >= 5: # CMYK: convert to RGB first\n",
    "                        pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "                    pix.save(filename)\n",
    "\n",
    "                    # Match with caption\n",
    "                    caption = caption_dict.get(str(figure_count), \"Caption not found\")\n",
    "\n",
    "                    figures.append({\n",
    "                        \"Figure_ID\": f\"Figure_{figure_count}\",\n",
    "                        \"Filename\": filename,\n",
    "                        \"Caption\": caption,\n",
    "                        \"Page\": page_num + 1,\n",
    "                        \"Image_Index\": img_index + 1\n",
    "                    })\n",
    "                    print(f\"    Saved {filename} | Caption: \\\"{caption[:30]}...\\\"\")\n",
    "                pix = None\n",
    "            except Exception as e:\n",
    "                print(f\"    Error extracting image {img_index} on page {page_num+1}: {e}\")\n",
    "                continue\n",
    "\n",
    "    doc.close()\n",
    "    print(f\"\\n EXTRACTION COMPLETE! Total figures: {len(figures)}\")\n",
    "    return figures\n",
    "\n",
    "def get_mock_figures_data():\n",
    "    \"\"\"Returns sample data for demonstration when no PDF is available.\"\"\"\n",
    "    print(\" Generating MOCK DATA for demonstration...\")\n",
    "    return [\n",
    "        {\n",
    "            \"Figure_ID\": \"Figure_1\",\n",
    "            \"Filename\": \"Figure_1.png\",\n",
    "            \"Caption\": \"Map showing the Yeshan iron tailings location and sample collection sites\",\n",
    "            \"Page\": 1,\n",
    "            \"Image_Index\": 1\n",
    "        },\n",
    "        {\n",
    "            \"Figure_ID\": \"Figure_2\",\n",
    "            \"Filename\": \"Figure_2.png\",\n",
    "            \"Caption\": \"Particle size distributions of mineralogical phases\",\n",
    "            \"Page\": 2,\n",
    "            \"Image_Index\": 1\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Module 2: Table Detection & Parsing\n",
    "Detects if an extracted figure is a table and parses it into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_table_in_image(image_path):\n",
    "    \"\"\"Detects if an image contains a table structure using OpenCV.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(image_path): return False, \"File not found\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None: return False, \"Cannot read image\"\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Detect horizontal and vertical lines\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))\n",
    "        detect_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "        detect_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
    "\n",
    "        horizontal_lines = cv2.countNonZero(detect_horizontal)\n",
    "        vertical_lines = cv2.countNonZero(detect_vertical)\n",
    "\n",
    "        has_structure = (horizontal_lines > 100 and vertical_lines > 50)\n",
    "        return has_structure, f\"H-lines: {horizontal_lines}, V-lines: {vertical_lines}\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Error: {e}\"\n",
    "\n",
    "def parse_table_to_csv(image_path, output_csv_path):\n",
    "    \"\"\"Parses table image to CSV using Tesseract OCR.\"\"\"\n",
    "    try:\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        extracted_text = pytesseract.image_to_string(image_path, config=custom_config)\n",
    "        lines = extracted_text.strip().split('\\n')\n",
    "        table_data = []\n",
    "\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                cells = re.split(r'\\s{2,}|\\t', line.strip())\n",
    "                cells = [cell.strip() for cell in cells if cell.strip()]\n",
    "                if cells: table_data.append(cells)\n",
    "\n",
    "        if table_data:\n",
    "            max_cols = max(len(row) for row in table_data)\n",
    "            for row in table_data:\n",
    "                while len(row) < max_cols: row.append('')\n",
    "            columns = [f'Column_{i+1}' for i in range(max_cols)]\n",
    "            df = pd.DataFrame(table_data, columns=columns)\n",
    "            df.to_csv(output_csv_path, index=False)\n",
    "            return True, df\n",
    "        return False, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing table: {e}\")\n",
    "        return False, None\n",
    "\n",
    "def process_tables(figures_data, output_dir):\n",
    "    print(\"=\"*60)\n",
    "    print(\"MODULE 2: TABLE DETECTION & PARSING\")\n",
    "    print(\"=\"*60)\n",
    "    results = []\n",
    "    table_keywords = ['table', 'tabular', 'data', 'summary', 'results']\n",
    "\n",
    "    for figure in figures_data:\n",
    "        caption_is_table = any(k in figure['Caption'].lower() for k in table_keywords)\n",
    "        structure_is_table, _ = detect_table_in_image(figure['Filename'])\n",
    "        is_table = caption_is_table or structure_is_table\n",
    "\n",
    "        result = figure.copy()\n",
    "        result['Is_Table'] = is_table\n",
    "\n",
    "        if is_table:\n",
    "            csv_name = os.path.join(output_dir, f\"{figure['Figure_ID']}_table.csv\")\n",
    "            success, _ = parse_table_to_csv(figure['Filename'], csv_name)\n",
    "            result['CSV_File'] = csv_name if success else None\n",
    "            print(f\" {figure['Figure_ID']} -> Detected as Table. Parsed: {success}\")\n",
    "        else:\n",
    "            print(f\" {figure['Figure_ID']} -> Not a table\")\n",
    "        \n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Module 3: OCR & Text Extraction\n",
    "Extracts text from figures that are NOT tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_figure(image_path):\n",
    "    try:\n",
    "        if not os.path.exists(image_path): return []\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "        text = pytesseract.image_to_string(thresh, config=r'--oem 3 --psm 6')\n",
    "        return [line.strip() for line in text.split('\\n') if len(line.strip()) > 1]\n",
    "    except: return []\n",
    "\n",
    "def process_ocr(figures_data):\n",
    "    print(\"=\"*60)\n",
    "    print(\"MODULE 3: OCR & TEXT EXTRACTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for figure in figures_data:\n",
    "        if not figure.get('Is_Table', False):\n",
    "            text = extract_text_from_figure(figure['Filename'])\n",
    "            figure['Extracted_Text'] = text\n",
    "            print(f\" {figure['Figure_ID']} -> Extracted {len(text)} text lines\")\n",
    "    return figures_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Module 4: Metadata Enrichment\n",
    "Categorizes figures and extracts keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_figure(caption, is_table):\n",
    "    caption = caption.lower()\n",
    "    if is_table: return \"table\"\n",
    "    if any(w in caption for w in ['map', 'location']): return \"map\"\n",
    "    if any(w in caption for w in ['chart', 'plot', 'graph']): return \"chart\"\n",
    "    if any(w in caption for w in ['diagram', 'flowchart']): return \"diagram\"\n",
    "    return \"image\"\n",
    "\n",
    "def enrich_metadata(figures_data):\n",
    "    print(\"=\"*60)\n",
    "    print(\"MODULE 4: METADATA ENRICHMENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for figure in figures_data:\n",
    "        # Keyword Extraction\n",
    "        text_content = figure['Caption'] + \" \" + \" \".join(figure.get('Extracted_Text', []))\n",
    "        words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text_content.lower())\n",
    "        keywords = [w for w in words if w not in stop_words]\n",
    "        from collections import Counter\n",
    "        figure['Keywords'] = [w for w, c in Counter(keywords).most_common(5)]\n",
    "        \n",
    "        # Categorization\n",
    "        figure['Category'] = categorize_figure(figure['Caption'], figure.get('Is_Table', False))\n",
    "        print(f\" {figure['Figure_ID']} -> Category: {figure['Category']} | Keywords: {figure['Keywords']}\")\n",
    "    return figures_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Module 5 & 6: Complexity & Verification\n",
    "Estimates complexity and verifies content authenticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_complexity(figures_data):\n",
    "    print(\"=\"*60)\n",
    "    print(\"MODULE 5: COMPLEXITY ESTIMATION\")\n",
    "    print(\"=\"*60)\n",
    "    # Simplified logic for demonstration (ML model would require training data)\n",
    "    for figure in figures_data:\n",
    "        score = 1\n",
    "        if figure.get('Is_Table'): score += 2\n",
    "        if len(figure.get('Extracted_Text', [])) > 10: score += 1\n",
    "        if len(figure['Caption'].split()) > 20: score += 1\n",
    "        \n",
    "        figure['Complexity_Score'] = min(score, 5)\n",
    "        levels = [\"Very Simple\", \"Simple\", \"Medium\", \"Complex\", \"Very Complex\"]\n",
    "        figure['Complexity_Level'] = levels[figure['Complexity_Score']-1]\n",
    "        print(f\" {figure['Figure_ID']} -> Score: {figure['Complexity_Score']} ({figure['Complexity_Level']})\")\n",
    "    return figures_data\n",
    "\n",
    "def verify_ai_content(figures_data):\n",
    "    print(\"=\"*60)\n",
    "    print(\"MODULE 6: AI CONTENT VERIFICATION\")\n",
    "    print(\"=\"*60)\n",
    "    # Placeholder for AI detection logic\n",
    "    for figure in figures_data:\n",
    "        caption = figure['Caption'].lower()\n",
    "        ai_indicators = ['moreover', 'furthermore', 'comprehensive']\n",
    "        is_ai = any(w in caption for w in ai_indicators)\n",
    "        figure['AI_Suspected'] = is_ai\n",
    "        print(f\" {figure['Figure_ID']} -> AI Suspected: {is_ai}\")\n",
    "    return figures_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "print(\"STARTING PIPELINE...\\n\")\n",
    "\n",
    "# 1. Extract\n",
    "figures_data = extract_figures_with_captions(PDF_PATH, OUTPUT_DIR)\n",
    "\n",
    "# 2. Table Detection\n",
    "figures_data = process_tables(figures_data, OUTPUT_DIR)\n",
    "\n",
    "# 3. OCR\n",
    "figures_data = process_ocr(figures_data)\n",
    "\n",
    "# 4. Metadata\n",
    "figures_data = enrich_metadata(figures_data)\n",
    "\n",
    "# 5. Complexity\n",
    "figures_data = estimate_complexity(figures_data)\n",
    "\n",
    "# 6. AI Verification\n",
    "figures_data = verify_ai_content(figures_data)\n",
    "\n",
    "# Save Final Results\n",
    "df = pd.DataFrame(figures_data)\n",
    "csv_path = os.path.join(OUTPUT_DIR, \"final_pipeline_results.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nPipeline Completed! Results saved to {csv_path}\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}